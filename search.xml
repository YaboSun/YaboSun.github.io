<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[GeoSpark学习--初识GeoSpark]]></title>
    <url>%2F2018%2F04%2F02%2FGeoSpark%E5%AD%A6%E4%B9%A0--%E5%88%9D%E8%AF%86GeoSpark%2F</url>
    <content type="text"><![CDATA[#背景#传统的不足：数据存储方面：1、现有的数据存储主要是多依赖关系型数据库，比如Oracle等，但是关系型数据库在海量数据管理、高并发读写以及扩展性方面有很大的局限2、传统的空间数据存储方式不但难以扩展，而且随着数据的激增读写性能存在极大瓶颈3、传统的分布式文件系统虽然可以存放在不同的节点上，但这种分布式文件系统所支持的扩展性有限数据分析方面：大数据时代的数据是处处连接的，每个连接都是一个传感器，这些传感器无时无刻都在进行数据的采集，所以说数据的变化很快，在这样的背景下，迫切需要GIS能够做到低延迟的分析处理工作 技术发展 1、存储去结构化非关系型数据库比如说HBase、Redis、MongoDB、InfoGrid，这些数据库不需要预先定义模式，并且可以在系统运行的时候动态增加或删除节点，避免了停机维护，提高了拓展性和可靠性另外这些非关系型数据库没有共享架构，数据一般是存储在本地服务器上，可以直接读取数据，提高了数据的读取性能。2、计算内存化对于Hadoop来说主要进行离线数据的计算，应对低延迟的应用场景比较困难，另外Hadoop使用MapReduce模型，该模型将复杂模型使用简单的映射规约，对于复杂的算法逻辑支持不充分，并且数据存储在硬盘上，很容易收IO瓶颈的影响，所以对于处理GIS数据乏力。而新的技术Spark启用了内存分布式数据集，支持更多的范式，而且配有一个数据处理模型，所以在处理GIS数据中性能更好。3、分析去模型化传统的GIS空间数据分析需要先建立分析模型，比如说考虑影响因子，权重，最后综合各影响因素进行建模，然而大数据环境下的数据是时刻在变化的，这样就无法满足，所以去模型化是最终的发展方向 GeoSpark 这里主要介绍GeoSpark以及我调试运行过程中遇到的问题 GeoSpark介绍GeoSpark是在Apache Spark第三方项目中的一个子项目，也是一个用于处理大规模空间数据的集群计算系统，目前最新版本更新到v1.1.0（2018年3月13日）。GeoSpark继承自Apache Spark，并拥有一系列具有创造性的空间弹性分布式数据集（SRDDs），借助机器这些数据集可以有效的加载，处理并分析大规模的空间数据。GeoSpark为Apache开发人员提供了API使得他们能够利用SRDDs方便的开发空间分析程序，这些程序为地理空间查询提供了有力的支持。 主要功能GeoSparkSQL最新版本的GeoSpark主要是包含了新的SQL功能，新增了四叉树和R树的索引解析并修复了一些bug。这个版本最主要的就是包含了一个完整的GeoSparkSQL版本，GeoSparkSQL完全支持Apache Spark SQL。SRDDs支持特殊的SRDDs，包括PointRDD,RectangleRDD,PolygonRDD以及LineStringRDD。空间分割支持的空间分割技术有四叉树、KDB树、R树、沃罗诺伊图（Voronoi diagram）、均匀网络（Uniform grids）空间索引支持四叉树、R树、以及空间K近邻查询 调试之路好，开搞，以下内容较多，纯属个人踩坑记录，想直接运行的跳到文章末尾即可1、搭建环境| 系统 | IDE | Spark | Scala | Jdk | Maven | Sbt ||—–|| Ubuntu16.04 | IntelliJ IDEA2017.3 | 2.2.1 | 2.11.12 | 1.8.0_151 | 3.5.3 | 1.1.1|基本的环境都搭建好了，没遇到什么问题，具体安装教程网上都有，就不多说，不过在我安装过程中也遇到了坑，这里就不一一说明，有遇到问题的可以问我2、Git Clone项目地址这是什么鬼？怎么迁项目还出了问题，应该是权限的问题稍微等一会儿就Clone好了，这时候在home可以看到项目的位置的话看个人习惯，开始迁下来以后权限是只读的，这使得后面使用IDEA导入时候会出现权限的问题，所以需要修改权限修改权限命令sudo chmod -R 777 &lt;yourfilename&gt;这里简单说一下这个命令 chmod 修改文件和文件夹读写执行属性，777 指的就是二进制编码，总共有3位111就是可读可写可编译，即拥有全权限，可写 w=4可读 r=2可执行 x=1 ，详细介绍chown和chmod区别get !3、Package + Compile这里说一下，我最开始没有跑GeoSpark，而是调的其中的一个案例，如果只是想简单的在本地IDE运行该项目的话，完全不需要这个步骤，然而……我还是照着做了这部分基本没什么问题，只要你maven还有Sbt装好了，按照项目说明一步步执行，就都可以编译通过4、导入项目import project-&gt;GeoSparkTemplateProject/geospark/java-&gt;import project from external model-&gt;maven这里需要注意运行Java部分的代码时，导入项目为maven项目，然后一路next即可，选择SDK时候添加你的jdk1.85、build+run/src/main/Example 点击运行，好，报错 123456789101112131415161718192021222324252627282930Exception in thread "main" java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.()V from class org.apache.hadoop.mapred.FileInputFormatat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:312)at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)at scala.Option.getOrElse(Option.scala:121)at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)at scala.Option.getOrElse(Option.scala:121)at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)at scala.Option.getOrElse(Option.scala:121)at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)at org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1115)at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)at org.apache.spark.rdd.RDD.aggregate(RDD.scala:1108)at org.apache.spark.api.java.JavaRDDLike$class.aggregate(JavaRDDLike.scala:426)at org.apache.spark.api.java.AbstractJavaRDDLike.aggregate(JavaRDDLike.scala:45)at org.datasyslab.geospark.spatialRDD.SpatialRDD.analyze(SpatialRDD.java:430)at org.datasyslab.geospark.spatialRDD.SpatialRDD.analyze(SpatialRDD.java:404)at org.datasyslab.geospark.spatialRDD.PointRDD.(PointRDD.java:300)at example.Example.testSpatialRangeQuery(Example.java:156)at example.Example.main(Example.java:128) 仔细看，主要是IllegalAccessError，Google搜索1、https://blog.csdn.net/superzyl/article/details/53764731开始解决，一句话就是项目中的依赖出现了问题，guava冲突，但是在我的pom.xml文件中并没有这个依赖啊？ 无果。。2、http://www.bubuko.com/infodetail-1909839.html还是那个原因，但是给出了一点具体的解决办法查看jar包，发现有多个版本的guava，这部分后面项目开发者都进行了修改，现在看到的只有一个版本我当时是有4个，然后我具体不知道是哪个版本需要，就保留了16.0.1，把其余的都删了，再重新进行整合，编译，结果还是同样的错误到这里为止，我就不清楚该怎么解决，期间删了项目重新下载，删除其他版本的guava还是没用3、问导师这个时候我知道问题肯定出在依赖上，应该是版本依赖冲突或者缺少依赖的问题，但是不知道具体在哪里导师给我添加了GeoSpark还有Babylon的依赖，这里添加的话就是去maven的官网，对应依赖的地方搜索你想要添加的，就会得到对应的代码，然后复制粘贴到项目的pom.xml文件中即可，这部分我是刚接触还不太明白，后面慢慢熟悉。然而添加以后还是不行，我又开始自己琢磨4、看原项目说明文档这时候重新仔细的又看了一下原项目的说明，按照说的都做了不知道问题出在哪里5、问大佬实在不知道该怎么办，看了issue中也没有这个错误的回答，问了下师兄说需要打包编译吧，我这里比较不确定，索性我直接开了个issue，当时其实抱着问问的心态，压根儿没想着大佬会回复我，因为国内好多博客下面提问，从来没有收到回复=-=不要嘲笑我蹩脚的英文。。。没过几分钟就收到了回复，他说根本还是Spark依赖冲突的问题，让我理解dependency scopeScope几种模式：1、test范围指的是测试范围有效，在编译和打包时都不会使用这个依赖2、compile范围指的是编译范围有效，在编译和打包时都会将依赖存储进去3、provided依赖：在编译和测试的过程有效，最后生成war包时不会加入，诸如：servlet-api，因为servlet-api，tomcat等web服务器已经存在了，如果再打包会冲突4、runtime在运行的时候依赖，在编译的时候不依赖一般情况下默认是compile我按照他说的又重新安装了IDEA，把我原来的配置文件删除，再重新导入项目，直接运行，还是报错。。。没办法了，只能再继续提问收到回复赶紧试了一下 #总结#最新版的项目只要配置好环境，迁下来运行就可以了说说这个过程，花了很久的时间，虽然最后还是没能自己解决，但是过程确实学到了很多的东西，这只是本地IDE中运行项目，后面需要在Spark cluster运行，到现在很多东西还是很模糊，慢慢一点点学习积累吧！]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>GeoSpark</tag>
        <tag>maven</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android学习系列——ImageView用法]]></title>
    <url>%2F2018%2F01%2F30%2FAndroid%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ImageView%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[用Android开发也有一段时间，因为是从一开始就做项目，很多东西就是模仿着做，也没有仔细研究，准备把一些开发过程中遇到的需要注意区分的细节写下来，让思路清晰一些，以后用到也可以看看。 ImageView用法 ImageView就是Android中用来显示图片的一个控件 区分属性android:src和android:background设置俩个ImageView，分别用不同属性显示效果如下：可以看出src属性是将图片加载，不会随区域的变化而改变，background是使用图片填充 ImageView 和ImageButton都可以设置点击，用法其实没什么区别，唯一区别就是ImageButton 拥有默认背景，而ImageView 没有，如下所示显示效果可以看到ImageButton是有背景色的另外，通过ImageButton 的类定义我们可以看到ImageButton 继承自ImageView而 ImageView 类又是继承自View 类]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>ImageView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GithubPages+Hexo搭建个人博客]]></title>
    <url>%2F2018%2F01%2F28%2FGithubPages%2BHexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[如果是有个人服务器的话，建议选择WP（wordpress）搭建个人博客，可以参考这篇文章VPS+LNMP+WordPress搭建个人网站。没有的话，Hexo确实是一个很好的选择，一来简洁大方，十分优雅，二来能够自己折腾，可以设计的地方很多。好，话不多说，接下来详细介绍我搭建个人博客的过程。我的GithubPages+Hexo博客欢迎访问我的Hexo博客 安装环境win10企业版 64位Node.js v8.9.3Git version2.15.0 相关步骤 安装Node.js 步骤1、到Node.js官方网址下载对应版本一般我们下载最新的LTS（长期支持）版本即可，本教程以Version8.9.3对应的msi64bit安装为例，其他版本类似步骤2、双击下载的安装包将出现如下界面：步骤3、一路点击next即可，注意选择安装路径，这个看个人喜好，我一般软件安装在D盘，我这里选择的安装路径是D:\nodejs步骤4、检查是否安装成功win+R快捷键输入cmd1输入 node -v 输入时注意中间的空格即可显示安装的Node.js版本 安装Git 步骤1、到官方网址下载对应的版本Git各平台下载地址：https://git-scm.com/downloadWindows平台Git下载地址：https://git-scm.com/download/win安装过程不需要多说什么，一路下一步即可。安装成功后在桌面或文件夹中点击鼠标右键可以看到Git Bash Here选项。步骤2、检查Git版本 1输入 git --version 输入注意是双- GitHubPages配置 步骤1、进入GitHub官网注册账号，具体注册这里不再赘述。官网连接 https://github.com/步骤2、新建项目注意这里的Repository名字格式一定是账户名.github,io比如我的就是：yabosun.github.io在建好的项目右侧有Settings向下拉可看到GitHub Pages点击对应的网址你会发现该项目已经被部署到网络上，你可以通过外网来访问它。 安装Hexo 在自己认为合适的地方创建一个文件夹，用来存放之后博客的文档以及配置文件，我是在F盘新建了文件夹，并命名为BlogWorkspace。然后点击进入创建的文件夹，点击鼠标右键选择Git Bash Here 1输入 npm install hexo -g 开始安装Hexo 这个过程需要几分钟时间不等，看个人网络状况。安装完成后，检查是否安装成功 1输入 hexo -v 初始化该文件夹1输入 hexo init 这个过程也有点漫长需要等待几分钟，最后出现Start blogging with Hexo！表示安装成功。 开始安装所需要的组件1输入 npm install 首次体验Hexo1输入 hexo g 可以开启本地服务器1输入 hexo s 点击http://localhost:4000/ 可以正式体验hexo，出现Hexo的界面就表示安装成功了 Hexo连接GithubPages 将Hexo与GithubPages联系起来，首次运行的话这里需要设置Git的user name和emailctrl+C结束之前的sever 1输入 git config --global user.name "yabosun" 这里的username为你自己的GitHub用户名 1输入 git config --g global user.email "yabosun@163.com" 这里user.email为你GitHub账户绑定的邮箱 检查是否有.ssh文件1输入 cd ~/.ssh 生成密钥1输入 ssh-keygen -t rsa -C "yabosun@163.com" 连续回车 添加密钥到ssh-agent1输入 eval "$(ssh-agent -s)" 添加生成的SSH key到ssh-agent1输入 ssh-add ~/.ssh/id_rsa 登陆Github，点击头像下的settings，添加ssh新建一个ssh将C:\Users\yabosun\ssh路径下（这里要对应自己电脑的路径）的 id_rsa.pub文件中的内容复制到key 1输入ssh -T git@github.com 注意这里不用改任何名称。 配置Deploy 在你的博客所在文件夹根目录，例如我的是在F:\BlogWorkspace找到_config.yml文件，点击编辑，我是用的SublimeText3打开的，在文件末尾输入： 这里需要注意的是格式一定是：后跟一个空格，是它固定的格式，我一开始就在这里掉了坑，名称对应自己的GitHub项目名称，登陆你的GitHub账户，进入之前创建的Repository，点击Clone or download，选择Clone with SSH并复制就是你的repository 到这里基本上博客已经搭建成功，接下来安装扩展 1输入 npm install hexo-deployer-git --save 使用MarkDown编辑器编写好文章，编辑器最开始可以使用CSDN或者简书等博客内置的编辑器，Windows上推荐使用MarkDownPad2编辑器，不过我用了一下，别的功能还好，如果是要插入图片或者一些高级功能需要升级（付费），所以我现在基本就是在csdn编辑，然后导出MD文件，并上传到Github。另外你也可以直接使用命令生成MD文档： 1输入 hexo n "title" 这里的title是你文章的标题，这个时候你可以看到在F:\BlogWorkspace\source\_posts这个文件夹下会生成你命名的MD文章，打开可以直接编辑，具体的MarkDown语法可以参考这篇文章http://franky47.cn/2018/01/20/How%20to%20use%20MarkdownEditer/#more 生成并部署你的文章到GitHub服务器上1输入 hexo g -d 部署成功后访问你的地址：http://用户名.github.io，即可看到你文章的界面。到这里，基本的Hexo网站已经搭建完成。 参考使用Hexo+Github一步步搭建自己的博客Node.js安装配置]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>GithubPages</tag>
        <tag>Hexo</tag>
        <tag>个人博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前言]]></title>
    <url>%2F2018%2F01%2F27%2F%E5%89%8D%E8%A8%80%2F</url>
    <content type="text"><![CDATA[今天是2018年1月27日，武汉迎来了一场久违的大雪，好久之前就想着搭建博客，写写自己平时的一些心得体会。但是奈何一直沉（mang）迷（yu）学（suo）习（shi），直到上周才断断续续的搭建起最初的版本欢迎访问，后续再慢慢的更新优化。今天也算是博客网站初次搭建好第一次开始写自己的博客，所以还是蛮有纪念意义的。趁着今天这个日子，写一下自己的一些感想，包括对过去半年的总结，以及对2018年的憧憬。 总结过去 认知 日子真的是过的蛮快，经常就是一看日期，卧槽，又周日了？！细细回想，这半年来还是经历了很多。最初读研的想法就是觉得自己在大学阶段实在是没有学到什么，不知道自己怎么去找到一份满意的工作，所以读研的最开始还是怀着一颗努力学习的心的，看各种教学视频，看牛人的博客，制定自己的学习目标，摸索编译器的使用，看别人的学习经验，也是在这个阶段打定主意以后更多的从事跟Java有关的工作，可能也没什么原因，就是简单的觉得看着舒服。 懵逼 跟导师说明自己的想法后，很快给了我一个锻炼的机会，用Java实现一个算法，当时满怀欣喜，但是等到真正下手的时候却不知道该怎么做，所以那段时间也是一直都没啥进展，只是知道算法的流程，真的写代码时候一脸懵逼，写代码我觉得最初还是要有看的见的东西，才能提起兴趣，就这样很快半个多月就过去了，在这里要特别的感谢自己研究生的导师，并不是像别人说的研究生导师与学生是老板与员工的关系，老师真的很认真的给我讲解，甚至亲手教我一行一行的怎么实现一个简单的算法，蓝而，我最后还是没能把那个算法写出来。 迷茫 就这样到了正式开学，我还是脑子一片迷茫，进入实验室项目组，看了一段时间项目的代码，等到写月底总结的时候，突然发现，自己啥新的功能也没有实现，交代的任务也是做的一塌糊涂，真的毫无成就感，很多时候甚至怀疑自己是不是不适合敲代码，不懂该怎么下手，感觉东西学了很快就忘。还有就是本身对MFC实在提不起兴趣。 新奇 再到后来就没有做公司的项目，跑去跟导师做事情，这个过程也是收获蛮多的，学会了使用Github？SVN？好吧，你会说这些不算，老师让我去学了一下一款轻量级数据库SQlite，学了一些语法，然后就开始着手将已有的地质数据导入到这个数据库，当然这个时候实现都是用的C++，简单说，就是模仿老师写的代码，实现基本相似的功能，好，终于有了一些进展，看到自己成功把数据一行一行用代码导入数据库心里还是蛮开心的，但是，这个乱码是什么鬼！就不能给我一个完美的机会？当然在老师的帮助下修改了，后面就做了一段时间的小蜜蜂，哦不，砖瓦工更合适些。一天老师把我叫去，说这段时间你也模仿实现了一些，接下来就自己写，你实现一下这个功能，生成一个断层面，what？不懂。虽然嘴上嗯，心里还是没太搞明白。 磨练 差不多就到了快10月，后面就是自己的兼职实习阶段，感谢威总带我，走上了Android开发之路，去公司还是跟实验室不一样的，公司催的很紧，你必须得出东西，所以压力还是有点的，仗着脸皮厚，有时候没写出来还是拖了些天才提交，代码质量自然不用多说，现在回头看看之前写的，有点想打死自己，虽然被疯狂怼还是努力的做，也感觉自己收获很大，至少能看别人的代码，自己照着实现，然后能调通这个功能了，虽然经常因为命名混乱，考虑不周被怼，但是还是有些成就感，学到了很多Android基础的编程，这部分会在后面的博客中详细记录。 致谢 首先要感谢我家小七，今天也是相恋537天，感谢一路的陪伴，感谢对我的照顾。再次就是感谢遇到自己现在的导师，感谢对我的包容，对我的细心指导。最想感谢的还有就是威总，在我编程学习阶段给我很多的帮助，帮我调bug，虽然每次一脸嫌弃哈哈。还有就是感谢公司，感谢老王，让我看到自己身上最大的不足，就是学一个东西，没有认真的弄明白，只是简单的去模仿，没有真正的搞懂。也感谢遇到133的一群机电大佬（不是基佬），一起开黑，一起上分。OK，矫情的话就说到这。 展望未来2018简单计划： 旅游 争取抽时间出去旅游2次，目前考虑的城市有西安、成都、杭州、上海，具体待定，我带上钱，你带上我@王七宝 学习 深入学习Android，包括安卓的一些优化学习Java，多线程编程、网络编程学习web开发相关，包括JS、HTML等学习python，具体还没有了解，涉及到深度学习，人工智能学习在Linux系统编程开发扎实计算机基础，抽时间把计算机网络、计算机操作系统、数据结构等计算机基础课程学习一下，通过牛客网编程至少通过100 当然最大需要改变的就是以后学习东西要努力去深入了解，不要还是走马观花。想法总是美好的，现实可能很残酷，希望等到2019年看这篇博客时能没那么多后悔，而更多的是收获满满。加油！]]></content>
      <categories>
        <category>Hello World</category>
      </categories>
      <tags>
        <tag>日常随笔</tag>
      </tags>
  </entry>
</search>
